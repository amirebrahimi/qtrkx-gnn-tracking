{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0b88cf-bc31-46a7-b805-747663004efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --quiet\n",
    "!pip install tensorflow-quantum --quiet\n",
    "!pip install sklearn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b64732-ada9-40f6-a750-b9ef2a91a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing configs: \n",
      "train_dir: data_new/train\n",
      "valid_dir: data_new/valid\n",
      "dataset: mu200_1pT\n",
      "log_dir: logs/test/run1/\n",
      "run_type: new_run\n",
      "gpu: 0\n",
      "n_files: 10\n",
      "n_valid: 5\n",
      "n_train: 5\n",
      "batch_size: 1\n",
      "lr_c: 0.01\n",
      "n_iters: 3\n",
      "n_epoch: 10\n",
      "TEST_every: 5\n",
      "hid_dim: 4\n",
      "network: OGQGNN\n",
      "optimizer: Adam\n",
      "loss_func: BinaryCrossentropy\n",
      "n_thread: 8\n",
      "log_verbosity: 2\n",
      "EN_qc: {'PQC_id': '10', 'IEC_id': 'simple_encoding_y', 'MC_id': 'measure_all', 'n_layers': 3, 'repetitions': 0, 'n_qubits': 4}\n",
      "NN_qc: {'PQC_id': '10', 'IEC_id': 'simple_encoding_y', 'MC_id': 'measure_all', 'n_layers': 3, 'repetitions': 0, 'n_qubits': 4}\n",
      "Log dir: logs/test/run1/\n",
      "Training data input dir: data_new/train\n",
      "Validation data input dir: data_new/train\n",
      "2022-02-25 11:47:23.499696 Deleted old log: logs/test/run1/log_gradients_5.csv\n",
      "2022-02-25 11:47:23.503550 Deleted old log: logs/test/run1/log_parameters_11.csv\n",
      "2022-02-25 11:47:23.507068 Deleted old log: logs/test/run1/log_parameters_2.csv\n",
      "2022-02-25 11:47:23.510532 Deleted old log: logs/test/run1/summary.csv\n",
      "2022-02-25 11:47:23.514306 Deleted old log: logs/test/run1/log_gradients_9.csv\n",
      "2022-02-25 11:47:23.518411 Deleted old log: logs/test/run1/log_parameters_6.csv\n",
      "2022-02-25 11:47:23.521675 Deleted old log: logs/test/run1/log_gradients_10.csv\n",
      "2022-02-25 11:47:23.524965 Deleted old log: logs/test/run1/log_gradients_1.csv\n",
      "2022-02-25 11:47:23.528014 Deleted old log: logs/test/run1/log_gradients_7.csv\n",
      "2022-02-25 11:47:23.531786 Deleted old log: logs/test/run1/log_parameters_4.csv\n",
      "2022-02-25 11:47:23.535733 Deleted old log: logs/test/run1/log_parameters_8.csv\n",
      "2022-02-25 11:47:23.539097 Deleted old log: logs/test/run1/log_validation.csv\n",
      "2022-02-25 11:47:23.543066 Deleted old log: logs/test/run1/log_gradients_3.csv\n",
      "2022-02-25 11:47:23.547345 Deleted old log: logs/test/run1/log_parameters_0.csv\n",
      "2022-02-25 11:47:23.551256 Deleted old log: logs/test/run1/log_parameters_3.csv\n",
      "2022-02-25 11:47:23.554839 Deleted old log: logs/test/run1/log_gradients_6.csv\n",
      "2022-02-25 11:47:23.558189 Deleted old log: logs/test/run1/log_parameters_7.csv\n",
      "2022-02-25 11:47:23.561605 Deleted old log: logs/test/run1/log_gradients_11.csv\n",
      "2022-02-25 11:47:23.565367 Deleted old log: logs/test/run1/log_gradients_2.csv\n",
      "2022-02-25 11:47:23.568476 Deleted old log: logs/test/run1/log_parameters_5.csv\n",
      "2022-02-25 11:47:23.572739 Deleted old log: logs/test/run1/log_gradients_8.csv\n",
      "2022-02-25 11:47:23.577006 Deleted old log: logs/test/run1/log_gradients_0.csv\n",
      "2022-02-25 11:47:23.580666 Deleted old log: logs/test/run1/log_training.csv\n",
      "2022-02-25 11:47:23.584287 Deleted old log: logs/test/run1/log_parameters_9.csv\n",
      "2022-02-25 11:47:23.588152 Deleted old log: logs/test/run1/log_parameters_10.csv\n",
      "2022-02-25 11:47:23.594367 Deleted old log: logs/test/run1/log_parameters_1.csv\n",
      "2022-02-25 11:47:23.598524 Deleted old log: logs/test/run1/log_gradients_4.csv\n",
      "QC10_PQC\n",
      "                                                      ┌───────────┐                                      ┌───────────┐                                       ┌────────────┐\n",
      "(0, 0): ───Ry(x0)───Ry(theta0)───────────@─────────────@──────────────Ry(theta4)───────────@──────────────@──────────────Ry(theta8)────────────@──────────────@───────────────Ry(theta12)───\n",
      "                                         │             │                                   │              │                                    │              │\n",
      "(1, 0): ───Ry(x1)───Ry(theta1)───────@───@─────────────┼Ry(theta5)─────────────────────@───@──────────────┼Ry(theta9)──────────────────────@───@──────────────┼Ry(theta13)──────────────────\n",
      "                                     │                 │                               │                  │                                │                  │\n",
      "(2, 0): ───Ry(x2)───Ry(theta2)───@───@───Ry(theta6)────┼───────────────────────────@───@───Ry(theta10)────┼────────────────────────────@───@───Ry(theta14)────┼─────────────────────────────\n",
      "                                 │                     │                           │                      │                            │                      │\n",
      "(3, 0): ───Ry(x3)───Ry(theta3)───@─────────────────────@──────────────Ry(theta7)───@──────────────────────@──────────────Ry(theta11)───@──────────────────────@───────────────Ry(theta15)───\n",
      "                                                      └───────────┘                                      └───────────┘                                       └────────────┘\n",
      "QC10_PQC\n",
      "                                                      ┌───────────┐                                      ┌───────────┐                                       ┌────────────┐\n",
      "(0, 0): ───Ry(x0)───Ry(theta0)───────────@─────────────@──────────────Ry(theta4)───────────@──────────────@──────────────Ry(theta8)────────────@──────────────@───────────────Ry(theta12)───\n",
      "                                         │             │                                   │              │                                    │              │\n",
      "(1, 0): ───Ry(x1)───Ry(theta1)───────@───@─────────────┼Ry(theta5)─────────────────────@───@──────────────┼Ry(theta9)──────────────────────@───@──────────────┼Ry(theta13)──────────────────\n",
      "                                     │                 │                               │                  │                                │                  │\n",
      "(2, 0): ───Ry(x2)───Ry(theta2)───@───@───Ry(theta6)────┼───────────────────────────@───@───Ry(theta10)────┼────────────────────────────@───@───Ry(theta14)────┼─────────────────────────────\n",
      "                                 │                     │                           │                      │                            │                      │\n",
      "(3, 0): ───Ry(x3)───Ry(theta3)───@─────────────────────@──────────────Ry(theta7)───@──────────────────────@──────────────Ry(theta11)───@──────────────────────@───────────────Ry(theta15)───\n",
      "                                                      └───────────┘                                      └───────────┘                                       └────────────┘\n",
      "Model: \"GNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " InputNet (Dense)            multiple                  16        \n",
      "                                                                 \n",
      " EdgeNet (EdgeNet)           multiple                  81        \n",
      "                                                                 \n",
      " NodeNet (NodeNet)           multiple                  124       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "2022-02-25 11:47:30.943175 Starting testing the valid set with 5 subgraphs!\n",
      "/home/jovyan/qtrkx-gnn-tracking/test.py:91: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision_7 = tp/(tp+fp) # also named purity\n",
      "2022-02-25 11:48:08.064825: validation Test:  Loss: 0.6889,  AUC: 0.5124, Acc: 53.5564,  Precision: 0.5458 -- Elapsed: 0m37s\n",
      "2022-02-25 11:48:08.066788 Starting testing the train set with 5 subgraphs!\n",
      "/home/jovyan/qtrkx-gnn-tracking/test.py:91: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision_7 = tp/(tp+fp) # also named purity\n",
      "2022-02-25 11:48:48.035243: training Test:  Loss: 0.6928,  AUC: 0.5108, Acc: 50.5494,  Precision: 0.5135 -- Elapsed: 0m39s\n",
      "2022-02-25 11:48:48.037520: Training is starting!\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "/home/jovyan/qtrkx-gnn-tracking/train.py:55: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  if (np.mean(last_grads) / np.mean(first_grads) > threshold):\n",
      "2022-02-25 11:49:01.690688: Epoch: 1, Batch: 1, Loss: 0.6894, Elapsed: 0m13s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:49:20.066885: Epoch: 1, Batch: 2, Loss: 0.6978, Elapsed: 0m18s\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Adjoint.differentiate_analytic at 0x7f2e5c6ace50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:49:35.282231: Epoch: 1, Batch: 3, Loss: 0.6902, Elapsed: 0m15s\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Adjoint.differentiate_analytic at 0x7f2e5c6ace50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:49:52.760498: Epoch: 1, Batch: 4, Loss: 0.6877, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:50:08.346062: Epoch: 1, Batch: 5, Loss: 0.6862, Elapsed: 0m15s\n",
      "2022-02-25 11:50:08.489739 Starting testing the valid set with 5 subgraphs!\n",
      "/home/jovyan/qtrkx-gnn-tracking/test.py:91: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision_7 = tp/(tp+fp) # also named purity\n",
      "2022-02-25 11:50:45.361338: validation Test:  Loss: 0.6826,  AUC: 0.6446, Acc: 60.5470,  Precision: 0.6602 -- Elapsed: 0m36s\n",
      "2022-02-25 11:50:45.363952 Starting testing the train set with 5 subgraphs!\n",
      "/home/jovyan/qtrkx-gnn-tracking/test.py:91: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision_7 = tp/(tp+fp) # also named purity\n",
      "2022-02-25 11:51:25.719175: training Test:  Loss: 0.6838,  AUC: 0.6404, Acc: 59.8522,  Precision: 0.6217 -- Elapsed: 0m40s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "/home/jovyan/qtrkx-gnn-tracking/train.py:55: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  if (np.mean(last_grads) / np.mean(first_grads) > threshold):\n",
      "2022-02-25 11:51:39.081878: Epoch: 2, Batch: 1, Loss: 0.6834, Elapsed: 0m13s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:51:57.371105: Epoch: 2, Batch: 2, Loss: 0.6837, Elapsed: 0m18s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:52:14.659698: Epoch: 2, Batch: 3, Loss: 0.6780, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:52:29.764736: Epoch: 2, Batch: 4, Loss: 0.6775, Elapsed: 0m14s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:52:45.335229: Epoch: 2, Batch: 5, Loss: 0.6759, Elapsed: 0m15s\n",
      "2022-02-25 11:52:45.487526 Starting testing the valid set with 5 subgraphs!\n",
      "/home/jovyan/qtrkx-gnn-tracking/test.py:91: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision_7 = tp/(tp+fp) # also named purity\n",
      "2022-02-25 11:53:22.446780: validation Test:  Loss: 0.6725,  AUC: 0.6799, Acc: 62.3123,  Precision: 0.7155 -- Elapsed: 0m36s\n",
      "2022-02-25 11:53:22.449548 Starting testing the train set with 5 subgraphs!\n",
      "/home/jovyan/qtrkx-gnn-tracking/test.py:91: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision_7 = tp/(tp+fp) # also named purity\n",
      "2022-02-25 11:54:02.406199: training Test:  Loss: 0.6736,  AUC: 0.6736, Acc: 62.3725,  Precision: 0.6798 -- Elapsed: 0m39s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "/home/jovyan/qtrkx-gnn-tracking/train.py:55: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  if (np.mean(last_grads) / np.mean(first_grads) > threshold):\n",
      "2022-02-25 11:54:15.862579: Epoch: 3, Batch: 1, Loss: 0.6747, Elapsed: 0m13s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:54:33.165083: Epoch: 3, Batch: 2, Loss: 0.6689, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:54:48.161098: Epoch: 3, Batch: 3, Loss: 0.6678, Elapsed: 0m14s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:55:03.551349: Epoch: 3, Batch: 4, Loss: 0.6656, Elapsed: 0m15s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:55:21.565164: Epoch: 3, Batch: 5, Loss: 0.6696, Elapsed: 0m17s\n",
      "2022-02-25 11:55:21.714445 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 11:55:58.409443: validation Test:  Loss: 0.6577,  AUC: 0.7005, Acc: 64.9792,  Precision: 0.6909 -- Elapsed: 0m36s\n",
      "2022-02-25 11:55:58.412188 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 11:56:38.188998: training Test:  Loss: 0.6621,  AUC: 0.6900, Acc: 64.2005,  Precision: 0.6558 -- Elapsed: 0m39s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "/home/jovyan/qtrkx-gnn-tracking/train.py:55: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  if (np.mean(last_grads) / np.mean(first_grads) > threshold):\n",
      "2022-02-25 11:56:55.261657: Epoch: 4, Batch: 1, Loss: 0.6598, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:57:13.357384: Epoch: 4, Batch: 2, Loss: 0.6640, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:57:28.361791: Epoch: 4, Batch: 3, Loss: 0.6567, Elapsed: 0m14s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:57:43.860806: Epoch: 4, Batch: 4, Loss: 0.6534, Elapsed: 0m15s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:57:57.241615: Epoch: 4, Batch: 5, Loss: 0.6540, Elapsed: 0m13s\n",
      "2022-02-25 11:57:57.392954 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 11:58:33.884078: validation Test:  Loss: 0.6444,  AUC: 0.7300, Acc: 65.6989,  Precision: 0.7492 -- Elapsed: 0m36s\n",
      "2022-02-25 11:58:33.886865 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 11:59:13.661561: training Test:  Loss: 0.6481,  AUC: 0.7188, Acc: 65.5137,  Precision: 0.7110 -- Elapsed: 0m39s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "/home/jovyan/qtrkx-gnn-tracking/train.py:55: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  if (np.mean(last_grads) / np.mean(first_grads) > threshold):\n",
      "2022-02-25 11:59:31.677029: Epoch: 5, Batch: 1, Loss: 0.6519, Elapsed: 0m18s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 11:59:46.658556: Epoch: 5, Batch: 2, Loss: 0.6442, Elapsed: 0m14s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:00:03.958091: Epoch: 5, Batch: 3, Loss: 0.6392, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:00:17.443753: Epoch: 5, Batch: 4, Loss: 0.6383, Elapsed: 0m13s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:00:32.980290: Epoch: 5, Batch: 5, Loss: 0.6308, Elapsed: 0m15s\n",
      "2022-02-25 12:00:33.174774 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 12:01:10.359600: validation Test:  Loss: 0.6244,  AUC: 0.7563, Acc: 69.6885,  Precision: 0.7404 -- Elapsed: 0m37s\n",
      "2022-02-25 12:01:10.362519 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 12:01:50.948956: training Test:  Loss: 0.6309,  AUC: 0.7462, Acc: 68.9628,  Precision: 0.7083 -- Elapsed: 0m40s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "/home/jovyan/qtrkx-gnn-tracking/train.py:55: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  if (np.mean(last_grads) / np.mean(first_grads) > threshold):\n",
      "2022-02-25 12:02:08.366042: Epoch: 6, Batch: 1, Loss: 0.6289, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:02:22.128371: Epoch: 6, Batch: 2, Loss: 0.6271, Elapsed: 0m13s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:02:37.436673: Epoch: 6, Batch: 3, Loss: 0.6230, Elapsed: 0m15s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:02:53.265321: Epoch: 6, Batch: 4, Loss: 0.6130, Elapsed: 0m15s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:03:11.776586: Epoch: 6, Batch: 5, Loss: 0.6178, Elapsed: 0m18s\n",
      "2022-02-25 12:03:11.938537 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 12:03:49.285648: validation Test:  Loss: 0.6032,  AUC: 0.7831, Acc: 71.2257,  Precision: 0.7879 -- Elapsed: 0m37s\n",
      "2022-02-25 12:03:49.288488 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 12:04:29.698531: training Test:  Loss: 0.6078,  AUC: 0.7741, Acc: 70.8450,  Precision: 0.7574 -- Elapsed: 0m40s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "/home/jovyan/qtrkx-gnn-tracking/train.py:55: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  if (np.mean(last_grads) / np.mean(first_grads) > threshold):\n",
      "2022-02-25 12:04:43.250989: Epoch: 7, Batch: 1, Loss: 0.6093, Elapsed: 0m13s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:05:00.669399: Epoch: 7, Batch: 2, Loss: 0.6004, Elapsed: 0m17s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:05:16.455437: Epoch: 7, Batch: 3, Loss: 0.5909, Elapsed: 0m15s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:05:34.871570: Epoch: 7, Batch: 4, Loss: 0.5954, Elapsed: 0m18s\n",
      "Vanishing gradients (layer 0 - GNN/InputNet/kernel:0): 2 out of 12 (16.666666666666668%)\n",
      "Vanishing gradients (layer 1 - GNN/InputNet/bias:0): 1 out of 4 (25.0%)\n",
      "2022-02-25 12:05:50.136845: Epoch: 7, Batch: 5, Loss: 0.5872, Elapsed: 0m15s\n",
      "2022-02-25 12:05:50.307319 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 12:06:27.450199: validation Test:  Loss: 0.5746,  AUC: 0.8039, Acc: 73.5043,  Precision: 0.7881 -- Elapsed: 0m37s\n",
      "2022-02-25 12:06:27.453003 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 12:07:07.484875: training Test:  Loss: 0.5789,  AUC: 0.7978, Acc: 73.1288,  Precision: 0.7641 -- Elapsed: 0m40s\n",
      "2022-02-25 12:07:22.975469: Epoch: 8, Batch: 1, Loss: 0.5724, Elapsed: 0m15s\n",
      "2022-02-25 12:07:38.085581: Epoch: 8, Batch: 2, Loss: 0.5754, Elapsed: 0m14s\n",
      "2022-02-25 12:07:56.266787: Epoch: 8, Batch: 3, Loss: 0.5712, Elapsed: 0m18s\n",
      "2022-02-25 12:08:13.423533: Epoch: 8, Batch: 4, Loss: 0.5582, Elapsed: 0m16s\n",
      "2022-02-25 12:08:26.941072: Epoch: 8, Batch: 5, Loss: 0.5560, Elapsed: 0m13s\n",
      "2022-02-25 12:08:27.113351 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 12:09:03.570622: validation Test:  Loss: 0.5439,  AUC: 0.8216, Acc: 74.1343,  Precision: 0.7658 -- Elapsed: 0m36s\n",
      "2022-02-25 12:09:03.573481 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 12:09:43.664181: training Test:  Loss: 0.5480,  AUC: 0.8169, Acc: 73.8088,  Precision: 0.7486 -- Elapsed: 0m40s\n",
      "2022-02-25 12:10:00.737025: Epoch: 9, Batch: 1, Loss: 0.5458, Elapsed: 0m17s\n",
      "2022-02-25 12:10:15.755494: Epoch: 9, Batch: 2, Loss: 0.5451, Elapsed: 0m14s\n",
      "2022-02-25 12:10:33.762537: Epoch: 9, Batch: 3, Loss: 0.5416, Elapsed: 0m17s\n",
      "2022-02-25 12:10:49.257200: Epoch: 9, Batch: 4, Loss: 0.5227, Elapsed: 0m15s\n",
      "2022-02-25 12:11:02.648987: Epoch: 9, Batch: 5, Loss: 0.5257, Elapsed: 0m13s\n",
      "2022-02-25 12:11:02.821207 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 12:11:39.709654: validation Test:  Loss: 0.5151,  AUC: 0.8310, Acc: 74.2104,  Precision: 0.7511 -- Elapsed: 0m36s\n",
      "2022-02-25 12:11:39.712523 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 12:12:20.124950: training Test:  Loss: 0.5199,  AUC: 0.8265, Acc: 74.1094,  Precision: 0.7412 -- Elapsed: 0m40s\n",
      "2022-02-25 12:12:35.827905: Epoch: 10, Batch: 1, Loss: 0.5120, Elapsed: 0m15s\n",
      "2022-02-25 12:12:54.280128: Epoch: 10, Batch: 2, Loss: 0.5216, Elapsed: 0m18s\n",
      "2022-02-25 12:13:07.852997: Epoch: 10, Batch: 3, Loss: 0.5096, Elapsed: 0m13s\n",
      "2022-02-25 12:13:23.026479: Epoch: 10, Batch: 4, Loss: 0.5089, Elapsed: 0m15s\n",
      "2022-02-25 12:13:40.462233: Epoch: 10, Batch: 5, Loss: 0.4992, Elapsed: 0m17s\n",
      "2022-02-25 12:13:40.636078 Starting testing the valid set with 5 subgraphs!\n",
      "2022-02-25 12:14:17.634585: validation Test:  Loss: 0.4903,  AUC: 0.8263, Acc: 74.1751,  Precision: 0.7947 -- Elapsed: 0m36s\n",
      "2022-02-25 12:14:17.637352 Starting testing the train set with 5 subgraphs!\n",
      "2022-02-25 12:14:58.178637: training Test:  Loss: 0.4983,  AUC: 0.8202, Acc: 73.9591,  Precision: 0.7806 -- Elapsed: 0m40s\n",
      "2022-02-25 12:14:58.181298: Training completed!\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py configs/test_x_CERN.yaml 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbda33c6-ae3e-45c5-ae7c-22690d738b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!time python -m cProfile -s cumtime train.py configs/spsa_config.yaml 1 > profile.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc622c6-a234-4753-99bc-8739b2410c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [qBraid]",
   "language": "python",
   "name": "python3_qbraid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
